  "cells": [
      "cell_type": "markdown",
      "metadata": {},
      "source": "# PyAutoLens Einstein Ring Reconstruction\nThis notebook demonstrates a minimal end-to-end workflow for modelling a strong-lensing image with [PyAutoLens](https://pyautolens.readthedocs.io/).\n\nThe steps below load a public TIFF file, prepare it as a masked `Imaging` dataset, set up a simple lens + source model, and run a quick nested-sampling search to recover the source-plane reconstruction."
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Environment prerequisites\nThis notebook expects the `pyautolens`, `autoarray`, and `autofit` packages to be installed. If they are missing, install them first (uncomment the cell below)."
    },
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Uncomment to install the PyAutoLens stack if it is not already available.\n# %pip install --quiet 'autolens[examples]>=1.4.0'\n"
    },
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Imports\nWe keep dependencies light: PyAutoLens for lensing, `Pillow` for the TIFF input, `numpy` for array handling, and `matplotlib` for quick previews."
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import warnings\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\nimport autolens as al\nimport autofit as af\n\nwarnings.filterwarnings('ignore')\n"
    },
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Load and pre-process the input image\nWe centre-crop the provided `potm2503a.tif` around the Einstein ring and downsample to keep the fit fast. The pixel values are rescaled to [0, 1] for convenience."
    },
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Configure paths and basic preprocessing choices\ntif_path = Path('potm2503a.tif')\ncrop_size = 600  # pixels for a centred square cut-out\nresize_shape = (280, 280)  # shape after downsampling for a quick demo\n\nif not tif_path.exists():\n    raise FileNotFoundError(f'Missing example image at {tif_path}')\n\n# Load and centre-crop the TIFF\nraw_f = Image.open(tif_path).convert('F')\nraw = np.array(raw_f, dtype='float32')\ncy, cx = np.array(raw.shape) // 2\nhalf = min(crop_size // 2, cy, cx)\ncutout = raw[cy - half : cy + half, cx - half : cx + half]\n\n# Downsample to the working resolution and normalise to [0, 1]\ncutout_resized = np.array(Image.fromarray(cutout).resize(resize_shape, resample=Image.BICUBIC))\ncutout_rescaled = cutout_resized - cutout_resized.min()\ncutout_rescaled /= cutout_rescaled.max()\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4))\nax[0].imshow(raw, cmap='inferno', origin='lower')\nax[0].set_title('Full TIFF (raw)')\nax[0].axis('off')\nax[1].imshow(cutout_rescaled, cmap='inferno', origin='lower')\nax[1].set_title('Cropped + downsampled')\nax[1].axis('off')\nplt.show()\n"
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Build a PyAutoLens `Imaging` dataset\nWe assign reasonable pixel scales and PSF width (arcseconds) for a space-based observation and apply a circular mask to focus on the ring."
    },
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "PIXEL_SCALES = 0.04  # arcsec per pixel after downsampling\nPSF_FWHM_ARCSEC = 0.09\nBACKGROUND_RMS = 0.003\nMASK_RADIUS_ARCSEC = 3.2\n\nsigma_pixels = (PSF_FWHM_ARCSEC / PIXEL_SCALES) / 2.355\nmask_unmasked = al.Mask2D.all_false(shape_native=cutout_rescaled.shape, pixel_scales=PIXEL_SCALES)\n\ndata = al.Array2D(values=cutout_rescaled, mask=mask_unmasked)\nnoise_map = al.Array2D.full(fill_value=BACKGROUND_RMS, shape_native=cutout_rescaled.shape, pixel_scales=PIXEL_SCALES)\npsf = al.Kernel2D.from_gaussian(shape_native=(21, 21), sigma=sigma_pixels, pixel_scales=PIXEL_SCALES)\n\nimaging = al.Imaging(data=data, noise_map=noise_map, psf=psf)\nmask = al.Mask2D.circular(shape_native=cutout_rescaled.shape, pixel_scales=PIXEL_SCALES, radius=MASK_RADIUS_ARCSEC)\nimaging = imaging.apply_mask(mask)\n\nimaging_plotter = al.plot.ImagingPlotter(dataset=imaging)\nimaging_plotter.subplot_dataset()\n"
    },
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Define a simple lens + source model\nWe keep the parameterisation compact: an elliptical isothermal mass plus Sersic light for the lens galaxy, and a Sersic source. Gaussian priors centre parameters near typical Einstein ring values."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "lens = af.Model(al.Galaxy, redshift=0.5)\nlens.mass = af.Model(al.mp.Isothermal)\nlens.mass.centre = af.Model(af.GaussianPrior, mean=0.0, sigma=0.05)\nlens.mass.ell_comps = af.Model(af.GaussianPrior, mean=0.0, sigma=0.1)\nlens.mass.einstein_radius = af.Model(af.GaussianPrior, mean=1.3, sigma=0.3)\nlens.light = af.Model(al.lp.Sersic)\nlens.light.centre = af.Model(af.GaussianPrior, mean=0.0, sigma=0.05)\nlens.light.ell_comps = af.Model(af.GaussianPrior, mean=0.0, sigma=0.1)\nlens.light.intensity = af.Model(af.GaussianPrior, mean=0.05, sigma=0.03)\nlens.light.effective_radius = af.Model(af.GaussianPrior, mean=0.6, sigma=0.2)\nlens.light.sersic_index = af.Model(af.GaussianPrior, mean=2.5, sigma=0.6)\n\nsource = af.Model(al.Galaxy, redshift=1.0)\nsource.light = af.Model(al.lp.Sersic)\nsource.light.centre = af.Model(af.GaussianPrior, mean=0.0, sigma=0.05)\nsource.light.ell_comps = af.Model(af.GaussianPrior, mean=0.0, sigma=0.2)\nsource.light.intensity = af.Model(af.GaussianPrior, mean=0.4, sigma=0.1)\nsource.light.effective_radius = af.Model(af.GaussianPrior, mean=0.25, sigma=0.1)\nsource.light.sersic_index = af.Model(af.GaussianPrior, mean=1.5, sigma=0.4)\n\nmodel = af.Collection(galaxies=af.Collection(lens=lens, source=source))\nmodel\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Configure and run the non-linear search\n`DynestyStatic` keeps runtime manageable for a notebook. You can increase `nlive` for better precision at the cost of extra time. Results are written under `output/notebook_demo`."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "analysis = al.AnalysisImaging(dataset=imaging)\n\nsearch = af.DynestyStatic(\n    name='notebook_fit',\n    path_prefix='output/notebook_demo',\n    nlive=30,\n    walks=5,\n    sample='rwalk'\n)\n\nresult = search.fit(model=model, analysis=analysis)\nprint(result.info)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualise the reconstruction\nAfter the search, inspect the maximum-likelihood fit and the inferred source-plane light distribution."
    },
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "fit = result.max_log_likelihood_fit\nfit_plotter = al.plot.FitImagingPlotter(fit=fit)\nfit_plotter.subplot_fit()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "tracer = result.max_log_likelihood_tracer\ntracer_plotter = al.plot.TracerPlotter(tracer=tracer, grid=imaging.grids.uniform)\ntracer_plotter.subplot_tracer()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Wrap-up\nThis compact notebook loads a real Einstein ring image, prepares a masked dataset, defines a straightforward PyAutoLens model, and runs a nested sampler to recover the source-plane reconstruction. Tuning the pixel scales, mask radius, and priors lets you adapt the workflow to survey data or higher-fidelity modelling."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
  "nbformat": 4,
  "nbformat_minor": 5
